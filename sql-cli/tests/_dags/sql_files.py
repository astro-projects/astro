# NOTE: This is an auto-generated file. Please do not edit this file manually.
from pathlib import Path

from airflow import DAG
from airflow.utils import timezone
from astro import sql as aql
from astro.table import Table

DAGS_DIRECTORY = Path(__file__).parent.as_posix()

with DAG(
    dag_id="sql_files",
    start_date=timezone.parse("2020-01-01 00:00:00"),
    schedule_interval=None,
) as dag:
    a = aql.transform_file(
        file_path=f"{DAGS_DIRECTORY}/_target/a.sql",
        parameters={
        },
        conn_id="my_test_sqlite",
        op_kwargs={
            "output_table": Table(
                name="a",
            ),
        },
        task_id="a",
    )
    b = aql.transform_file(
        file_path=f"{DAGS_DIRECTORY}/_target/b.sql",
        parameters={
            "a": a,
        },
        op_kwargs={
            "output_table": Table(
                name="b",
            ),
        },
        task_id="b",
    )
    c = aql.transform_file(
        file_path=f"{DAGS_DIRECTORY}/_target/c.sql",
        parameters={
            "a": a,
            "b": b,
        },
        op_kwargs={
            "output_table": Table(
                name="c",
            ),
        },
        task_id="c",
    )
